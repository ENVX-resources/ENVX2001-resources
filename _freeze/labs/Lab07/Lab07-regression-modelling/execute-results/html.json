{
  "hash": "810bf1676831fb722e2de9f034d2d7a7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ENVX2001 Lab 07 - Regression model development\"\n# revised-by: aca\nsubtitle: ENVX2001 Applied Statistical Methods\ndescription: The University of Sydney\ndate: today\ndate-format: \"[Semester 1,] YYYY\"\n---\n\n\n\n## Learning outcomes\n\nIn this lab, you will work towards achieving learning outcomes [L03](), and [L05]().\n\n### Lab objectives\n\nIn this lab, we will:\n\n-   [ ] Identify best predictors for model - Exercise 1\n-   [ ] Fit model and check assumptions - Exercise 1\n-   [ ] Interpret model output - Exercise 1\n\n::: callout-tip\nPlease work on this exercise by creating your own R Markdown file.\n:::\n\n### Preparation\n\n- [ ] Install or update the `performance` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"performance\")\nlibrary(performance)\n```\n:::\n\n\nThis package is really good for checking your models. \nFor this lab, we will focus on the `check_model()` function, which gives us nice pretty diagnostic plots for models:\n\n::: panel-tabset\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris_lm<- lm(iris$Petal.Length~iris$Sepal.Length)\n```\n:::\n\n\n### `plot()`\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(iris_lm)\n```\n\n::: {.cell-output-display}\n![](Lab07-regression-modelling_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n```\n:::\n\n\n### `check_model()` from `performance`\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_model(iris_lm)\n```\n\n::: {.cell-output-display}\n![](Lab07-regression-modelling_files/figure-html/warning - false-1.png){width=672}\n:::\n:::\n\n\n:::\n\n\n## Exercise 1: Modelling bird abundance\n\nWe will now use the transformed data in `loyn` for this exercise. If you have not already figured out how to perform the transformation, or if something is wrong, you may use the `loyn` tab in the `mlr.xlsx` MS Excel document. Alternatively, the code to convert the data is below.\n\n::: callout-tip\nThis is the same data we used in the walkthrough exercise\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load library if needed\nlibrary(readxl)\n# reset the data import just in case it has been modified\nloyn <- read_xlsx(\"data/mlr.xlsx\", \"Loyn\")\n# make transformations\n\nloyn <- loyn %>%\n    mutate(\n        L10AREA = log10(AREA),\n        L10DIST = log10(DIST),\n        L10LDIST = log10(LDIST)\n    )\n\n# check\nglimpse(loyn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 56\nColumns: 10\n$ ABUND    <dbl> 5.3, 2.0, 1.5, 17.1, 13.8, 14.1, 3.8, 2.2, 3.3, 3.0, 27.6, 1.…\n$ AREA     <dbl> 0.1, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2…\n$ YR.ISOL  <dbl> 1968, 1920, 1900, 1966, 1918, 1965, 1955, 1920, 1965, 1900, 1…\n$ DIST     <dbl> 39, 234, 104, 66, 246, 234, 467, 284, 156, 311, 66, 93, 39, 4…\n$ LDIST    <dbl> 39, 234, 311, 66, 246, 285, 467, 1829, 156, 571, 332, 93, 39,…\n$ GRAZE    <dbl> 2, 5, 5, 3, 5, 3, 5, 5, 4, 5, 3, 5, 2, 1, 5, 5, 3, 3, 3, 2, 2…\n$ ALT      <dbl> 160, 60, 140, 160, 140, 130, 90, 60, 130, 130, 210, 160, 210,…\n$ L10AREA  <dbl> -1.0000000, -0.3010300, -0.3010300, 0.0000000, 0.0000000, 0.0…\n$ L10DIST  <dbl> 1.591065, 2.369216, 2.017033, 1.819544, 2.390935, 2.369216, 2…\n$ L10LDIST <dbl> 1.591065, 2.369216, 2.492760, 1.819544, 2.390935, 2.454845, 2…\n```\n\n\n:::\n:::\n\n\n### Best single predictor?\n\n::: question\n### Question 1\n\nObtain the correlation between ABUND and all of the predictor variables using `cor()`. Based on these, what would you expect to be the best single predictor of ABUND?\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(loyn)\n```\n:::\n\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(loyn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               ABUND         AREA      YR.ISOL       DIST       LDIST\nABUND     1.00000000  0.255970206  0.503357741  0.2361125  0.08715258\nAREA      0.25597021  1.000000000 -0.001494192  0.1083429  0.03458035\nYR.ISOL   0.50335774 -0.001494192  1.000000000  0.1132175 -0.08331686\nDIST      0.23611248  0.108342870  0.113217524  1.0000000  0.31717234\nLDIST     0.08715258  0.034580346 -0.083316857  0.3171723  1.00000000\nGRAZE    -0.68251138 -0.310402417 -0.635567104 -0.2558418 -0.02800944\nALT       0.38583617  0.387753885  0.232715406 -0.1101125 -0.30602220\nL10AREA   0.74003580  0.584651024  0.278414517  0.3047850  0.33680642\nL10DIST   0.12672333  0.163054319 -0.019572228  0.8233190  0.29365797\nL10LDIST  0.11812448  0.101607829 -0.161116108  0.4968169  0.82059568\n               GRAZE        ALT    L10AREA     L10DIST    L10LDIST\nABUND    -0.68251138  0.3858362  0.7400358  0.12672333  0.11812448\nAREA     -0.31040242  0.3877539  0.5846510  0.16305432  0.10160783\nYR.ISOL  -0.63556710  0.2327154  0.2784145 -0.01957223 -0.16111611\nDIST     -0.25584182 -0.1101125  0.3047850  0.82331904  0.49681692\nLDIST    -0.02800944 -0.3060222  0.3368064  0.29365797  0.82059568\nGRAZE     1.00000000 -0.4071671 -0.5590886 -0.14263922 -0.03399082\nALT      -0.40716705  1.0000000  0.2751428 -0.21900701 -0.27404380\nL10AREA  -0.55908864  0.2751428  1.0000000  0.30216662  0.38247952\nL10DIST  -0.14263922 -0.2190070  0.3021666  1.00000000  0.60386637\nL10LDIST -0.03399082 -0.2740438  0.3824795  0.60386637  1.00000000\n```\n\n\n:::\n:::\n\n\nThe best single predictor would be `L10AREA` as this has the highest *r* (r = 0.74)\n:::\n\n### Assumptions and interpretation\n\n::: question\n### Question 2\n\nUse multiple linear regression to see whether ABUND can be predicted from L10AREA and GRAZE. Are the assumptions met? Is there a significant relationship? *Note: we are using these 2 predictors as they have the largest absolute correlations. Use `lm()` and specify the model as `ABUND ~ L10AREA + GRAZE`.*\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.mod1 <- lm(ABUND ~ GRAZE + L10AREA, data = loyn)\n\npar(mfrow = c(2, 2))\nplot(lm.mod1)\npar(mfrow = c(1, 1))\n\nsummary(lm.mod1)\n```\n:::\n\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.mod1 <- lm(ABUND ~ GRAZE + L10AREA, data = loyn)\n\npar(mfrow = c(2, 2))\nplot(lm.mod1)\n```\n\n::: {.cell-output-display}\n![](Lab07-regression-modelling_files/figure-html/mlmod-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n\nsummary(lm.mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ GRAZE + L10AREA, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4296  -4.3186  -0.6323   4.1273  13.0739 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  21.6029     3.0917   6.987 4.73e-09 ***\nGRAZE        -2.8535     0.7125  -4.005 0.000195 ***\nL10AREA       6.8901     1.2900   5.341 1.98e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.444 on 53 degrees of freedom\nMultiple R-squared:  0.6527,\tAdjusted R-squared:  0.6396 \nF-statistic: 49.81 on 2 and 53 DF,  p-value: 6.723e-13\n```\n\n\n:::\n:::\n\n\nThis is a significant model as both b1 and b2 are significant and the model is significant.\n\nThe residuals look reasonable. They are approximately normally distributed (both right hand plots), but possibly the variance is not totally constant and there are possibly a few values with high leverage (left hand plots).\n:::\n\n::: question\n### Question 3\n\nHow good is the model based on the (i) *r*^2^ (ii) adjusted *r*^2^? Use `summary()`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm.mod1)$r.squared\nsummary(lm.mod1)$adj.r.squared\n```\n:::\n\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nThe Adjusted *r*^2^ is lower than the *r*^2^, but we would opt for the adjusted *r*^2^ as it takes the number of predictors into account. Overall the model is ok, explaining 64.0% of variation in Abundance.\n:::\n\n::: question\n### Question 4\n\nWhich variable(s) has the most significant effect(s)? *(Refer specifically to the t probabilities in the table of predictors and their estimated parameters or coefficients in the output of `summary()`)*. Interpret the p-values in terms of dropping predictor variables.\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nBoth `L10AREA` and `GRAZE` are highly significant, `L10AREA` is the most significant. In terms of effect, a 1 unit change in `GRAZE` results in a -2.9 decrease in abundance (with `L10AREA` remaining constant), while a 1 unit change in `L10AREA`, (therefore a 10 unit change in `AREA`) results in a 6.9 increase in abundance (`GRAZE` holding constant).\n:::\n\n::: question\n## Question 5\n\nRepeat the multiple regression, but this time include YRS.ISOL as a predictor variable (it has the 3rd largest absolute correlation). This will allow you to assess the effect of YRS.ISOL with the other variables taken into account.\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.mod2 <- lm(ABUND ~ GRAZE + L10AREA + YR.ISOL, data=loyn)\n```\n:::\n\n:::\n\n::: question\n### Question 6\n\nCheck assumptions, do the residuals look ok? If you are happy with the assumptions, you can proceed to interpret the model output.\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(lm.mod2)\n```\n\n::: {.cell-output-display}\n![](Lab07-regression-modelling_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\n```\n:::\n\n\nThe residuals look OK, but YR.ISOL is borderline significant (p = 0.0768).\n:::\n\n::: question\n### Question 7\n\nCompare the *r*^2^ and adjusted *r*^2^ values with those you calculated for the 2 predictor model, Which is the better model? Why?\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm.mod2)\n```\n:::\n\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nBoth of these are greater than for model in step 3, so this is a better model.\n:::\n\n## Exercise 2: California streamflow\n\n\nThe following dataset contains 43 years of annual precipitation measurements (in mm) taken at (originally) 6 sites in the Owens Valley in California. I have reduced this to three variables labelled `lake_sabrina` (Lake Sabrina), `pine_creek` (Big Pine Creek), `rock_creek` (Rock Creek), and the dependent variable stream runoff volume (measured in ML/year) at a site near Bishop, California (labelled `runoff_volume`).\n\nNote the variables have already been log-transformed to increase normality of the residuals in the regressions.\n\nStart with a full model and manually remove the variables one at a time, checking every time whether removal of a variable actually improves the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in the data\nstream_data <- read_xlsx(\"data/california_streamflow.xlsx\", \"streamflow\")\nnames(stream_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"lake_sabrina\"  \"pine_creek\"    \"rock_creek\"    \"runoff_volume\"\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.mod_full <-lm(runoff_volume~lake_sabrina + pine_creek + rock_creek, data=stream_data)\ns.mod_full <-lm(runoff_volume~., data=stream_data) ## you can also use the . to indicate use all variables\nsummary(s.mod_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = runoff_volume ~ ., data = stream_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.09885 -0.03331  0.01025  0.03359  0.09495 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.25716    0.12360  26.352  < 2e-16 ***\nlake_sabrina  0.05631    0.03756   1.499  0.14185    \npine_creek    0.21085    0.06756   3.121  0.00339 ** \nrock_creek    0.43838    0.08798   4.983 1.32e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04861 on 39 degrees of freedom\nMultiple R-squared:  0.8817,\tAdjusted R-squared:  0.8726 \nF-statistic: 96.88 on 3 and 39 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n### Partial F-Tests\n\nThe above analysis tells us that both `pine_creek` & `rock_creek` are significant, according to the t-test, in the model and `lake_sabrina` is not? This involves performing Partial F-Tests as discussed in the lecture.\n\nThis can be done in **R** by using `anova()` on two model objects. To be able to compare the models and run the anova, you need to make objects of all the possible model combinations you want to compare.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.mod_reduced <- lm(runoff_volume ~ rock_creek + pine_creek, data=stream_data)\nanova(s.mod_reduced, s.mod_full)\n```\n:::\n\n\nThe last row gives the results of the partial F-test.\n\n::: question\n### Question 1\n\nShould we remove `lake_sabrina` from the model?\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nYes, we should remove lake_sabrina as the p-value is \\> 0.05 and opt for the simpler model.\n:::\n\n::: question\n### Question 2\n\nIs the p-value for the f-test the same as for the t-test?\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nYes, P-values for the t-statistic and for the Partial F-statistic are related (Partial F = t^2^)\n:::\n\n::: question\n### Question 3\n\nWrite out the hypotheses you are testing.\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nH~0~: $\\beta_{lake_sabrina} = 0$\\\nH~1~: $\\beta_{lake_sabrina} \\neq 0$\n:::\n\nPerform a Partial F-Test to work out if the removal of `lake_sabrina` and `pine_creek` improves upon the full model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.mod_reduced2  <- lm(runoff_volume ~ lake_sabrina + pine_creek,data=stream_data)\nanova(s.mod_reduced2, s.mod_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: runoff_volume ~ lake_sabrina + pine_creek\nModel 2: runoff_volume ~ lake_sabrina + pine_creek + rock_creek\n  Res.Df      RSS Df Sum of Sq     F    Pr(>F)    \n1     40 0.150845                                 \n2     39 0.092166  1   0.05868 24.83 1.321e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n::: question\n### Question 4\n\nWhich variable should be added to the model containing rock_creek?\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nlake_sabrina does not improve the model with only rock_creek ($\\beta_{lake_sabrina} = 0$), so we can say that we should add pine_creek to the model containing rock_creek.\n\nRemember: H0: No difference between the models, so choose the simplest H1: Full model is better\n:::\n\n::: question\n### Question 5\n\nCould things be even simpler? Perform a partial F-Test to see if a model containing rock_creek alone could be suitable.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.mod_reduced3  <- lm(runoff_volume ~ rock_creek,data=stream_data)\nanova(s.mod_reduced3, s.mod_full)\n```\n:::\n\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nFitting with only rock_creek does not improve model fit (P\\<0.05) and so we can conclude that the better model is the one with pine_creek and rock_creek as predictors, with lake_sabrina removed.\n:::\n\n::: question\n### Question 6\n\nWhat is your optimal model?\n:::\n\n::: {.content-visible when-profile=\"solution\"}\n### Answer {style=\"color:green;\"}\n\nThe best model is: $runoff_volume = \\beta_0 + \\beta_1 rock_creek + \\beta_2pine_creek+ error$\n:::\n\n<hr>\n\n## Review\n\n-   Simple linear regressions model the relationship between two variables\n\n    -   We can also make linear models with more than one predictor\n\n-   We can use histograms and correlation matrices to do some preliminary exploration of the data\n\n-   If any variables are skewed, we can transform them\n\n-   Looking at a correlation matrix to identify the best predictors (for both simple and multiple linear regression)\n\n-   Fit model using `lm()` function\n\n-   Check assumptions:\n\n    -   Collinearity (multiple linear regression only)\n    -   Linearity\n    -   Independence\n    -   Normality\n    -   Equal variance\n- Use `summary()` to look at model output and interpret it\n  - F-test : overall model significance\n  - Coefficients table : individual predictors' significance\n  - R^2^ : How much variation in the data is explained by the model?\n\nThat's it for today! Great work fitting simple and multiple linear regression! Next week we jump into stepwise selection!\n\n### Attribution\n",
    "supporting": [
      "Lab07-regression-modelling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}