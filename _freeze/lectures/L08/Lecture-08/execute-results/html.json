{
  "hash": "3588ec599429ebedb9c517b937f34f85",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression: model development\"\nauthor: Liana Pozza\nformat:\n  ochre-revealjs: default\n  ochre-typst:\n    fig-format: png\n# format: revealjs\n# fontsize: 16pt\nexecute:\n  echo: true\n  warning: false\n  message: false\n  scrolling: true\n---\n\n\n\n# Variable selection\n\n> \"The hardest thing to learn in life is which bridge to cross and which to burn.\"\n\n-- [David Russell](https://en.wikipedia.org/wiki/David_Russell_(guitarist))\n\n## Workflow {auto-animate=\"true\"}\n\n1.  [Model development]{style=\"color: #D0D3D4;\"}\n    -   [Explore: visualise, summarise]{style=\"color: #D0D3D4;\"}\n    -   [Transform predictors: linearise, reduce skewness/leverage]{style=\"color: #D0D3D4;\"}\n    -   [Model: fit, check assumptions, interpret, transform. Repeat.]{style=\"color: #D0D3D4;\"}\n2.  Variable selection\n    -   VIF: remove predictors with high variance inflation factor\n    -   Model selection: stepwise selection, AIC, principle of parsimony, assumption checks\n3.  [Predictive modelling]{style=\"color: #D0D3D4;\"}\n    -   [Predict: Use the model to predict new data]{style=\"color: #D0D3D4;\"}\n    -   [Validate: Evaluate the model’s performance]{style=\"color: #D0D3D4;\"}\n\n## Previously on ENVX2001... {auto-animate=\"true\"}\n\nWe fitted a multiple linear regression model to the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit <- lm(log(Ozone) ~ Temp + Solar.R + Wind, data = airquality)\nsummary(full_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(Ozone) ~ Temp + Solar.R + Wind, data = airquality)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.06193 -0.29970 -0.00231  0.30756  1.23578 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.2621323  0.5535669  -0.474 0.636798    \nTemp         0.0491711  0.0060875   8.077 1.07e-12 ***\nSolar.R      0.0025152  0.0005567   4.518 1.62e-05 ***\nWind        -0.0615625  0.0157130  -3.918 0.000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5086 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6644,\tAdjusted R-squared:  0.655 \nF-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n$$\\widehat{log(Ozone)}=-0.262 + 0.0492 \\cdot Temp + 0.00252 \\cdot Solar.R - 0.0616 \\cdot Wind$$\n\n## Question {auto-animate=\"true\"}\n\n$$\\widehat{log(Ozone)}=-0.262 + 0.0492 \\cdot Temp + 0.00252 \\cdot Solar.R - 0.0616 \\cdot Wind$$\n\n**Are all the variables/predictors needed?**\n\n### Principles\n\nA good model:\n\n-   Has only *useful* predictors: principle of parsimony\n-   Has *no redundant* predictors: principle of orthogonality (no multicollinearity)\n-   Is *interpretable* (principle of transparency; last week), or *predicts* well (principle of accuracy; next week)\n\n## On the principle of parsimony\n\n-   [Ockham's razor](https://en.wikipedia.org/wiki/Occam%27s_razor): \"Entities should not be multiplied unnecessarily.\"\n-   One should prefer the *simplest* explanation that fits the data if multiple explanations are equally good.\n\n> \"It is vain to do with more what can be done with fewer.\"\n\n-- [William of Ockham](https://en.wikipedia.org/wiki/William_of_Ockham) (1287--1347)\n\n## What happens when we add more predictors to a model?\n\nA simple example using polynomial regression.\n\n-   The more predictors we include, the more variance we can explain.\n-   However, the more predictors and complexity we include, the more overfitted the model becomes.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1030)\nxsquared <- function(x) {\n  x^2\n}\n# Generate xy data\nsim_data <- function(xsquared, sample_size = 100) {\n  x <- runif(n = sample_size, min = 0, max = 1)\n  y <- rnorm(n = sample_size, mean = xsquared(x), sd = 0.05)\n  data.frame(x, y)\n}\n# Generate predicted data (model)\ndf <- sim_data(xsquared, sample_size = 60)\nfit <- lm(y ~ 1, data = df)\nfit_1 <- lm(y ~ poly(x, degree = 1), data = df)\nfit_2 <- lm(y ~ poly(x, degree = 2), data = df)\nfit_many <- lm(y ~ poly(x, degree = 20), data = df)\ntruth <- seq(from = 0, to = 1, by = 0.01)\n# Combine the data and model fits into a single data frame\ndf <- data.frame(\n  x = df$x,\n  y = df$y,\n  fit = predict(fit),\n  fit_1 = predict(fit_1),\n  fit_2 = predict(fit_2),\n  fit_many = predict(fit_many)\n)\n\n# Reshape the data frame into long format\ndf_long <- pivot_longer(\n  df,\n  cols = starts_with(\"fit_\"),\n  names_to = \"model\",\n  values_to = \"value\"\n) %>%\n  mutate(\n    model = case_when(\n      model == \"fit\" ~ \"y = b\",\n      model == \"fit_1\" ~ \"y = b + mx\",\n      model == \"fit_2\" ~ \"y = b + mx + nx^2\",\n      model == \"fit_many\" ~ \"y = b + mx + nx^2 + ... + zx^20\",\n      TRUE ~ model\n    )\n  )\n# Plot\np <- ggplot(df_long, aes(x = x, y = value, color = model)) +\n  facet_wrap(~model, ncol = 2, scales = \"free\") +\n  geom_point(aes(y = y), alpha = .4, size = 2) +\n  geom_line(linewidth = .9, linetype = 1) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme(legend.position = \"none\") +\n  geom_blank()\np\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## Variance-bias trade-off\n\n![](images/bias_var.svg)\n\nIn concept...\n\n-   As complexity increases, bias ($\\sum{O-\\bar{P}}$) *decreases* (the mean of a model’s predictions is closer to the true mean).\n-   As complexity increases, prediction variance ($\\frac{\\sum{(P-\\bar{P})}^2}{n}$) increases.\n-   The **goal** is to find a model that isn't too simple or complex with a good balance between bias and variance.\n\n$$ \\text{Mean Squared Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Immeasureable Error} $$ In practice, the math and relationships are a bit more irregular.\n\n## How do we determine the best model?\n\nSome model quality measures you should be familiar with:\n\n-   **R^2^**: variance explained by the model with a maximum value of 1 = 100%\n-   **Residual standard error**: the mean error of the observed values from the predicted/fitted values (i.e. line of best fit).\n-   **Partial F-test**: compare the full model to a reduced model, works well when the number of predictors is small and simple models.\n\nSome other commonly used measures:\n\n-   **Information criteria**: AIC, BIC, etc. (more on this later).\n-   **Error measures**: useful when the aim for the model is to **predict**. The best model has the smallest residual error (or other similar metrics).\n\n## What models do we try?\n\n-   **Everything**: all possible combinations of predictors.\n    -   Each variable can either be included or excluded so the number of possible combinations is $2^n$\n    -   e.g. 3 predictors ($x_1$, $x_2$, $x_3$) could have 8 models\n        -   No variables i.e. mean $y$ the null hypothesis\n        -   1 variable: $x_1$; $x_2$; $x_3$\n        -   2 variables: $x_1$ + $x_2$; $x_1$ + $x_3$; $x_2$ + $x_3$\n        -   3 variables: $x_1$ + $x_2$ + $x_3$\n    -   So...not recommended\n-   **Stepwise regression**: add/remove predictors one at a time until removing a variable makes the model worse.\n-   **Select meaningful predictors** based on domain knowledge, correlation, or significance.\n-   More complex approaches are available for big data and machine learning.\n\n## Air quality: can we reduce the number of predictors? {auto-animate=true}\n\n**Full model:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(full_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(Ozone) ~ Temp + Solar.R + Wind, data = airquality)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.06193 -0.29970 -0.00231  0.30756  1.23578 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.2621323  0.5535669  -0.474 0.636798    \nTemp         0.0491711  0.0060875   8.077 1.07e-12 ***\nSolar.R      0.0025152  0.0005567   4.518 1.62e-05 ***\nWind        -0.0615625  0.0157130  -3.918 0.000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5086 on 107 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6644,\tAdjusted R-squared:  0.655 \nF-statistic: 70.62 on 3 and 107 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n-   `Wind` has the highest p-value, can we remove it?\n-   Full model: Multiple R-squared = 0.66, Adjusted R-squared = 0.66\n\n## {auto-animate=true}\n\n-   Full model: multiple R-squared = 0.66, adjusted R-squared = 0.66\n\n**Reduced model: take out `Wind`**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreduced_fit <- lm(log(Ozone) ~ Temp + Solar.R, data = airquality)\nsummary(reduced_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(Ozone) ~ Temp + Solar.R, data = airquality)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.83864 -0.33727  0.03444  0.29877  1.38210 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.7646527  0.4249016  -4.153 6.58e-05 ***\nTemp         0.0607386  0.0056663  10.719  < 2e-16 ***\nSolar.R      0.0024651  0.0005924   4.161 6.38e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5413 on 108 degrees of freedom\n  (42 observations deleted due to missingness)\nMultiple R-squared:  0.6163,\tAdjusted R-squared:  0.6092 \nF-statistic: 86.73 on 2 and 108 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n-   Reduced model: multiple R-squared = 0.62, adjusted R-squared = 0.61\n-   **Adjusted R-squared is lower, but is a 4% difference \"worth it\"? Is it significant?**\n\n## The R^2^ value\n\nThe R-squared value is the proportion of variance explained by the model.\n\n$$ R^2 = \\frac{SS_{reg}}{SS_{tot}} = 1 - \\frac{SS_{res}}{SS_{tot}} $$\n\nThe adjusted R-squared value is the proportion of variance explained by the model, adjusted for the number of predictors.\n\n$$R^2_{adj} = 1 - \\frac{SS_{res}}{SS_{tot}} \\frac{n-1}{n-p-1} $$\n\nwhere $n$ is the number of observations and $p$ is the number of predictors.\n\n# Partial F-test\n\n## Partial F-test {auto-animate=\"true\"}\n\nHow much of an improvement in adjusted $R^2$ is worth having an extra variable / more complex model?\n\n-   We can perform a hypothesis test to determine whether the improvement is significant.\n-   The F-test measures the full model against an intercept only model in terms of explained variance (residual sum of squares).\n-   The **partial F-test** compares the full model to a reduced model in terms of the trade-off between model complexity and variance explained (i.e. **adjusted** $R^2$).\n    -   $H_0$: no significant difference between the full and reduced models\n    -   $H_1$: the full model is significantly better than the reduced model\n    -   Calculating the F-stat:\n\n$$F = \\big| \\frac{SS_{reg,full} - SS_{reg,reduced}}{(df_{res,full} - df_{res,reduced})} \\big | \\div MS_{res, full}$$\n\n## Partial F-test: calculation {auto-animate=\"true\"}\n\n$$F = \\big| \\frac{SS_{reg,full} - SS_{reg,reduced}}{(df_{res,full} - df_{res,reduced})} \\big | \\div MS_{res, full}$$ where:\n\n-   $SS_{reg,full}$ is the sum of squares of the full model (total of predictors)\n-   $SS_{reg,reduced}$ is the sum of squares of the reduced model (total of predictors)\n-   $df_{res,full}$ is the degrees of freedom of the residuals of the full model\n-   $df_{res,reduced}$ is the degrees of freedom of the residuals of the reduced model\n-   $MS_{res, full}$ is the mean square of the residuals of the full model\n\n::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- anova(full_fit) %>% broom::tidy()\nfull\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  term         df sumsq meansq statistic   p.value\n  <chr>     <int> <dbl>  <dbl>     <dbl>     <dbl>\n1 Temp          1 45.8  45.8       177.   2.07e-24\n2 Solar.R       1  5.07  5.07       19.6  2.29e- 5\n3 Wind          1  3.97  3.97       15.4  1.58e- 4\n4 Residuals   107 27.7   0.259      NA   NA       \n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nreduced <- anova(reduced_fit) %>% broom::tidy()\nreduced\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  term         df sumsq meansq statistic   p.value\n  <chr>     <int> <dbl>  <dbl>     <dbl>     <dbl>\n1 Temp          1 45.8  45.8       156.   1.05e-22\n2 Solar.R       1  5.07  5.07       17.3  6.38e- 5\n3 Residuals   108 31.6   0.293      NA   NA       \n```\n\n\n:::\n:::\n\n:::\n:::\n\nEach row is the *individual effect* of each predictor on the response $log(Ozone)$ (whilst holding all other predictors constant).\n\n## By hand\n\n$$F = \\big| \\frac{SS_{reg,full} - SS_{reg,reduced}}{(df_{res,full} - df_{res,reduced})} \\big | \\div MS_{res, full}$$\n\n-   $SS_{reg,full} = 45.8 + 5.07 + 3.97 = 54.84$\n-   $SS_{reg,reduced} = 45.8 + 5.07 = 50.87$\n-   $df_{res,full} = 107$\n-   $df_{res,reduced} = 108$\n-   $MS_{res, full} = 0.259$\n\n$F = |\\frac{54.84 - 50.87}{(107-108)}| \\div 0.259 = 15.33$\n\n## In R (manually)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nss_full <- sum(full$sumsq[1:3])\nss_reduced <- sum(reduced$sumsq[1:2])\ndf_full <- full$df[4]\ndf_reduced <- reduced$df[3]\nms_full <- full$meansq[4]\nF <- abs((ss_full - ss_reduced) / ((df_full - df_reduced))) / ms_full\nF     # F-statistic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15.35026\n```\n\n\n:::\n\n```{.r .cell-code}\npf(F, df1 = 1, df2 = df_full, lower.tail = FALSE) # corresponding p-value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0001576806\n```\n\n\n:::\n:::\n\n\n(There is a slight difference due to rounding)\n\n## In R with functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(reduced_fit, full_fit) # reduced goes first else will see negative df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: log(Ozone) ~ Temp + Solar.R\nModel 2: log(Ozone) ~ Temp + Solar.R + Wind\n  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n1    108 31.645                                 \n2    107 27.675  1    3.9703 15.35 0.0001577 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n-   The partial F-test is significant (p-value \\< 0.05), so we can reject the null hypothesis and conclude that the full model is significantly better, even if adjusted R^2^ improves by 4%.\n\n## But wait... {auto-animate=\"true\"}\n\nLooking back at the original model, we can see that the partial regression coefficients are the *same* as the partial F-test results!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(reduced_fit, full_fit) # partial F-test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: log(Ozone) ~ Temp + Solar.R\nModel 2: log(Ozone) ~ Temp + Solar.R + Wind\n  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n1    108 31.645                                 \n2    107 27.675  1    3.9703 15.35 0.0001577 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(full_fit)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Estimate   Std. Error    t value     Pr(>|t|)\n(Intercept) -0.262132313 0.5535668608 -0.4735332 6.367975e-01\nTemp         0.049171124 0.0060875025  8.0773888 1.069103e-12\nSolar.R      0.002515177 0.0005567301  4.5177673 1.616797e-05\nWind        -0.061562470 0.0157129654 -3.9179409 1.576806e-04\n```\n\n\n:::\n:::\n\n\nThis is because the reduced model is *nested* within the full model so the partial F-test is equivalent to a partial regression coefficient test.\n\n## Nested models\n\n-   Previous example is a simple example of a **nested model**.\n-   A model is nested within another model if the predictors in the first model are a subset of the predictors in the second model.\n-   This makes comparing the two models easier, as we can compare the regression coefficients of the two models.\n\n### Example\n\n-   If the original model is y \\~ a + b + c:\n    -   Nested: y \\~ a + b\n    -   Nested: y \\~ a\n    -   *Not* nested: y \\~ a + b + **d** -- because **d** is not in the full model\n\n::: callout-important\n**Partial F-tests will *only* make sense/work for nested models!**\n:::\n\n# Another example: Bird abundance\n\n## About\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloyn <- read.csv(\"data/loyn.csv\")\nstr(loyn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t56 obs. of  7 variables:\n $ ABUND  : num  5.3 2 1.5 17.1 13.8 14.1 3.8 2.2 3.3 3 ...\n $ AREA   : num  0.1 0.5 0.5 1 1 1 1 1 1 1 ...\n $ YR.ISOL: int  1968 1920 1900 1966 1918 1965 1955 1920 1965 1900 ...\n $ DIST   : int  39 234 104 66 246 234 467 284 156 311 ...\n $ LDIST  : int  39 234 311 66 246 285 467 1829 156 571 ...\n $ GRAZE  : int  2 5 5 3 5 3 5 5 4 5 ...\n $ ALT    : int  160 60 140 160 140 130 90 60 130 130 ...\n```\n\n\n:::\n:::\n\n\n-   Can we predict the abundance of birds in forest patches cleared for agriculture, based on patch size, area, grazing and other variables?\n-   Loyn ([1987](https://www.researchgate.net/profile/Richard-Loyn/publication/279541149_Effects_of_patch_area_and_habitat_on_bird_abundances_species_numbers_and_tree_health_in_fragmented_Victoria_forests/links/563ae1bc08ae337ef2985592/Effects-of-patch-area-and-habitat-on-bird-abundances-species-numbers-and-tree-health-in-fragmented-Victoria-forests.pdf))\n    -   DIST: Distance to nearest patch (km)\n    -   LDIST: Distance to a larger patch (km)\n    -   AREA: Patch area (ha)\n    -   GRAZE: Grazing pressure 1 (light) – 5 (heavy) – ALT: Altitude (m)\n    -   YR.ISOL: Years since isolation (years)\n    -   ABUND: Density of forest birds in a forest patch (birds/patch)\n\n## Data exploration\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloyn %>%\n  pivot_longer(-ABUND) %>%\n  ggplot(aes(x = value, y = ABUND)) +\n  geom_point() +\n  facet_wrap(~name, scales = \"free\") +\n  labs(y = \"ABUND\")\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n-   The predictors are on very different scales, which can cause problems for the model.\n-   The relationships don't look particularly linear...and outliers.\n-   We will perform log~10~ transforms of `AREA`, `LDIST`, and `DIST`.\n\n## Log~10~ transformation\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# perform transformations\nloyn <- loyn %>%\n  mutate(AREA_L10 = log10(AREA),\n         LDIST_L10 = log10(LDIST),\n         DIST_L10 = log10(DIST))\n\n# View distributions again\nloyn %>%\n  select(-ALT, -GRAZE, -YR.ISOL) %>%\n  pivot_longer(-ABUND) %>%\n  mutate(name = factor(name, levels = unique(name))) %>%  # Preserve original order\n  ggplot(aes(x = value, y = ABUND)) +\n  geom_point() +\n  facet_wrap(~name, scales = \"free\") +\n  labs(y = \"ABUND\")\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## Checking assumptions - no transformation\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nloyn_fit <- lm(ABUND ~ YR.ISOL + GRAZE + ALT + AREA + LDIST + DIST, data = loyn)\nsummary(loyn_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + GRAZE + ALT + AREA + LDIST + DIST, \n    data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.6638  -4.6409  -0.0883   4.2858  20.1042 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -1.097e+02  1.133e+02  -0.968  0.33791   \nYR.ISOL      6.693e-02  5.684e-02   1.177  0.24472   \nGRAZE       -3.447e+00  1.107e+00  -3.114  0.00308 **\nALT          4.772e-02  3.089e-02   1.545  0.12878   \nAREA         8.866e-04  4.657e-03   0.190  0.84980   \nLDIST        1.418e-03  1.310e-03   1.082  0.28451   \nDIST         3.811e-03  5.418e-03   0.703  0.48514   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.947 on 49 degrees of freedom\nMultiple R-squared:  0.5118,\tAdjusted R-squared:  0.452 \nF-statistic: 8.561 on 6 and 49 DF,  p-value: 2.24e-06\n```\n\n\n:::\n:::\n\n##\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nperformance::check_model(loyn_fit, check = c(\"linearity\", \"qq\", \"homogeneity\", \"outliers\")) # check specific assumptions\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n## Checking assumptions - transformation\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nloyn_fit <- lm(ABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10 + LDIST_L10 + DIST_L10, data = loyn)\nsummary(loyn_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10 + LDIST_L10 + \n    DIST_L10, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6506  -2.9390   0.5289   2.5353  15.2842 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -125.69725   91.69228  -1.371   0.1767    \nYR.ISOL        0.07387    0.04520   1.634   0.1086    \nGRAZE         -1.66774    0.92993  -1.793   0.0791 .  \nALT            0.01951    0.02396   0.814   0.4195    \nAREA_L10       7.47023    1.46489   5.099 5.49e-06 ***\nLDIST_L10     -0.64842    2.12270  -0.305   0.7613    \nDIST_L10      -0.90696    2.67572  -0.339   0.7361    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.384 on 49 degrees of freedom\nMultiple R-squared:  0.6849,\tAdjusted R-squared:  0.6464 \nF-statistic: 17.75 on 6 and 49 DF,  p-value: 8.443e-11\n```\n\n\n:::\n:::\n\n\n##\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nperformance::check_model(loyn_fit, check = c(\"linearity\", \"qq\", \"homogeneity\", \"outliers\")) # check specific assumptions\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n# Other Assumptions\n\n> LINE... + leverage + collinearity\n\n## Leverage\n\n-   The leverage plot shows the influence of each observation (i.e. point) on the model.\n-   Points with high leverage can have a large effect on the model when removed.\n-   Identified by the Cook's distance statistic -- named after the American statistician R. Dennis Cook, who introduced the concept in 1977.\n\n::: callout-tip\nThe leverage plot is a useful tool for identifying outliers and influential points, but can also be used to check for other issues such as heteroskedasticity (equal variances) and non-linearity!\n:::\n\n## Reading the leverage plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1,2))\nplot(loyn_fit, which = c(4,5))\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n-   Visually, points with Cook's distance \\> 0.5 are considered influential by default, but this is a somewhat arbitrary threshold.\n-   In practice, you should use a threshold that is appropriate for your data and model.\n\n## Outlier detection using `performance`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_model(loyn_fit, check = c(\"outliers\", \"pp_check\"))\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_outliers(loyn_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.919).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n## Collinearity\n\n-   Two predictors that have a *perfect* linear relationship (i.e. $r$ = 1 or -1) breaks the assumption of collinearity\n-   Even strong correlations between predictors can lead to unstable estimates and large standard errors.\n-   Variance inflation factors (VIFs) are a measure of collinearity in the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrplot::corrplot(cor(loyn), method = \"number\")\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n## Calculating VIF\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::vif(loyn_fit) |> round(2) # numbers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  YR.ISOL     GRAZE       ALT  AREA_L10 LDIST_L10  DIST_L10 \n     1.80      2.52      1.47      1.91      2.01      1.65 \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(performance::check_collinearity(loyn_fit)) # visual\n```\n\n::: {.cell-output-display}\n![](Lecture-08_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n-   $1$ = no correlation with other predictors.\n-   $>10$ is a sign for high, not tolerable correlation of model predictors (which need to be removed and the model refitted).\n\n## The best model?\n\nIf we remove the least significant variable...\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nfull6 <- loyn_fit\npart5 <- update(full6, . ~ . - LDIST_L10)\npart4 <- update(part5, . ~ . - DIST_L10)\npart3 <- update(part4, . ~ . - ALT)\npart2 <- update(part3, . ~ . - YR.ISOL)\npart1 <- update(part2, . ~ . - GRAZE)\n\nformulas <- c(part1$call$formula, \n              part2$call$formula, \n              part3$call$formula, \n              part4$call$formula, \n              part5$call$formula, \n              loyn_fit$call$formula)\nformulas <-\n  c(\"ABUND ~ AREA_L10\",\n    \"ABUND ~ AREA_L10 + GRAZE\",\n    \"ABUND ~ AREA_L10 + GRAZE + YR.ISOL\",\n    \"ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT\",\n    \"ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT + DIST_L10\",\n    \"ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT + DIST_L10 + LDIST_L10\")\n\nrs <- bind_rows(glance(part1), \n          glance(part2), \n          glance(part3), \n          glance(part4),\n          glance(part5), \n          glance(full6)) %>%\n        mutate(Model = formulas) %>%\n        select(Model, r.squared, adj.r.squared)\n\nknitr::kable(rs, digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|Model                                                           | r.squared| adj.r.squared|\n|:---------------------------------------------------------------|---------:|-------------:|\n|ABUND ~ AREA_L10                                                |      0.55|          0.54|\n|ABUND ~ AREA_L10 + GRAZE                                        |      0.65|          0.64|\n|ABUND ~ AREA_L10 + GRAZE + YR.ISOL                              |      0.67|          0.65|\n|ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT                        |      0.68|          0.66|\n|ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT + DIST_L10             |      0.68|          0.65|\n|ABUND ~ AREA_L10 + GRAZE + YR.ISOL + ALT + DIST_L10 + LDIST_L10 |      0.68|          0.65|\n\n\n:::\n:::\n\n\n-   R-squared increases with addition of predictors.\n-   Adj. R-squared *varies* with addition of predictors.\n\n## The problem\n\n-   Other combinations of predictors exist but are not shown.\n-   Need *automated way* to select the best model -- 6 predictors gives us 2\\^6 = **64 models** to choose from!\n-   Options:\n    -   Backward elimination\n    -   Forward selection\n    -   Combination (R default)\n\n# Backward elimination\n\n## Steps for backward elimination\n\n1.  Start with full model.\n2.  For each predictor, test the effect of its removal on the model fit.\n3.  Remove the predictor that has the *least* effect on the model fit i.e. the **least informative** predictor, unless it is nonetheless supplying significant information about the response.\n4.  Repeat steps 2 and 3 until no predictors can be removed without significantly affecting the model fit.\n\nIn backward selection, the model fit is assessed using the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). **Here we focus on the AIC.**\n\n## About AIC\n\n-   Most **popular** model selection criterion (can be used for non-nested models)\n-   Developed by [Hirotsugu Akaike](https://en.wikipedia.org/wiki/Hirotugu_Akaike) under the name of \"an information criterion\" (AIC)\n-   Founded on information theory which is concerned with the transmission, processing, utilization, and extraction of information.\n\n$$AIC = 2k - 2\\ln(L)$$\n\n## About AIC {auto-animate=\"true\"}\n\n$$AIC = 2k - 2\\ln(L)$$\n\n- $k$ is the number of parameters in the model (predictors + intercept)\n- $L$ is the maximum value of the likelihood function\n  - If we predict using the (current) model, what is the probability density of the prediction compared to the original distribution?\n  - $ln(L)$ = goodness of fit (higher is better)\n- For the number of parameters in the model ($2k$) subtract the goodness of fit $2ln(L)$\n  - **The smaller the AIC, the better the model fits the data.**\n  -   A *relative* measure and *unitless*, so it is not worth trying to interpret alone.\n- Can be calculated with the `AIC()` function in R\n\n## About AIC - FYI\n\nIn linear regression, AIC is sometimes calculated as:\n\n$$AIC = n\\log(\\frac{RSS}{n}) + 2k$$\n\nwhere $RSS$ is the residual sum of squares, $2k$ is the number of parameters in the model, and $n$ is the number of observations.\n\n-   The difference between this equation and the previous equation is a constant, or scaling\n-   The `step()` function in R uses this equation (hence you may notice a difference in AIC values!)\n\n## Back to our example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nback_step <- step(loyn_fit, direction = \"backward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=214.14\nABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10 + LDIST_L10 + DIST_L10\n\n            Df Sum of Sq    RSS    AIC\n- LDIST_L10  1      3.80 2000.7 212.25\n- DIST_L10   1      4.68 2001.5 212.27\n- ALT        1     27.02 2023.9 212.90\n<none>                   1996.8 214.14\n- YR.ISOL    1    108.83 2105.7 215.11\n- GRAZE      1    131.07 2127.9 215.70\n- AREA_L10   1   1059.75 3056.6 235.98\n\nStep:  AIC=212.25\nABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10 + DIST_L10\n\n           Df Sum of Sq    RSS    AIC\n- DIST_L10  1     12.64 2013.3 210.60\n- ALT       1     35.12 2035.8 211.22\n<none>                  2000.7 212.25\n- YR.ISOL   1    121.64 2122.3 213.55\n- GRAZE     1    132.44 2133.1 213.84\n- AREA_L10  1   1193.04 3193.7 236.44\n\nStep:  AIC=210.6\nABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10\n\n           Df Sum of Sq    RSS    AIC\n- ALT       1     57.84 2071.1 210.19\n<none>                  2013.3 210.60\n- GRAZE     1    123.48 2136.8 211.94\n- YR.ISOL   1    134.89 2148.2 212.23\n- AREA_L10  1   1227.11 3240.4 235.25\n\nStep:  AIC=210.19\nABUND ~ YR.ISOL + GRAZE + AREA_L10\n\n           Df Sum of Sq    RSS    AIC\n<none>                  2071.1 210.19\n- YR.ISOL   1    129.81 2200.9 211.59\n- GRAZE     1    188.45 2259.6 213.06\n- AREA_L10  1   1262.97 3334.1 234.85\n```\n\n\n:::\n:::\n\n\n## \n\nPrinting `back_step` reveals the final model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nback_step\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + GRAZE + AREA_L10, data = loyn)\n\nCoefficients:\n(Intercept)      YR.ISOL        GRAZE     AREA_L10  \n -134.26065      0.07835     -1.90216      7.16617  \n```\n\n\n:::\n:::\n\n\n## Backward elimination: coefficients\n\n**Full model**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nsjPlot::tab_model(\n  loyn_fit, back_step, \n  show.ci = FALSE, \n  show.aic = TRUE,\n  dv.labels = c(\"Full model\",\n                \"Reduced model\")\n)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Full model</th>\n<th colspan=\"2\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">Reduced model</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Estimates</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">(Intercept)</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;125.70</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.177</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;134.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.126</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">YR ISOL</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.07</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.109</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.08</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.077</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">GRAZE</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.67</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.079</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.90</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.034</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">ALT</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.02</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.419</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">AREA L10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">7.47</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">7.17</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">LDIST L10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.65</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.761</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">DIST L10</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.91</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.736</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">56</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"2\">56</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> / R<sup>2</sup> adjusted</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.685 / 0.646</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">0.673 / 0.654</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">AIC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">375.064</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"2\">371.109</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\nThe reduced model retains more explanatory power than the full model!\n\n# Summary\n\n## Model selection\n\n**Model development**\n\n1.  Start with full model and check assumptions (e.g. normality, homoscedasticity, linearity, etc.).\n2.  Look for additional issues (e.g. multicollinearity, outliers, etc.) -- correlations, leverage, VIF plots.\n3.  Consider transformations (e.g. log, sqrt, etc.).\n4.  Test assumptions again.\n\n**Model selection**\n\n5.  Use VIF as an initial step to get rid of highly correlated predictors.\n6.  Perform variable selection using backward elimination (good and fast), because:\n    -   Using R^2^ as a criterion is *not* recommended (it is not a good measure of model fit, only a good measure of variance explained).\n    -   Using partial F-test is good, but slow.\n\n# Next lecture\n\n## Next lecture: model training and prediction\n\n-   How to incorporate calibration and validation into your workflow\n-   Determining prediction intervals and performance metrics\n\n# Thanks!\n\n**Questions? Comments?**\n\nSlides made with [Quarto](https://quarto.org)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}